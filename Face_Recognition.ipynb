{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary modules for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the frame from the camera in BGR and GRAY format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('gray', gray)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    \n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Creating an object of harrcascade classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(20,20))\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_img = img[y:y+h, x:x+h]\n",
    "    \n",
    "    cv2.imshow('Video', img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    \n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_label_db = {}\n",
    "face_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Name of the user : Vikas\n",
      "\n",
      " [INFO] Intializing Face Capture. Look at the camera and wait...\n",
      "\n",
      " [INFO] Exiting Program and cleanup stuff\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "user_name = input('Enter Name of the user : ')\n",
    "face_id += 1\n",
    "\n",
    "if face_id not in users_label_db:\n",
    "    users_label_db[face_id] = user_name\n",
    "    \n",
    "print('\\n [INFO] Intializing Face Capture. Look at the camera and wait...')\n",
    "\n",
    "face_count = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(20,20))\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "        face_count += 1\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        cv2.imwrite(os.path.join('Datasets', 'User.') + str(face_id) + '.' + str(face_count) + '.jpg', roi_gray)\n",
    "        cv2.imshow('Image', img)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27 :\n",
    "        break\n",
    "    elif face_count >= 30:\n",
    "        break\n",
    "        \n",
    "print('\\n [INFO] Exiting Program and cleanup stuff')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying face_id and face_labels of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Vikas\n",
      "2 Vikas\n"
     ]
    }
   ],
   "source": [
    "for name,face_id in users_label_db.items():\n",
    "    print(name, face_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_for_dataset = 'Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n [INFO] Training Faces to the Face Recognizer')\n",
    "\n",
    "image_paths = [os.path.join(path_for_dataset, file) for file in os.listdir(path_for_dataset)]\n",
    "\n",
    "face_samples = []\n",
    "face_ids = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    \n",
    "    PIL_img = Image.open(image_path).convert('L')\n",
    "    img_numpy = np.array(PIL_img, 'uint8')\n",
    "    \n",
    "    face_id = int(os.path.split(image_path)[-1].split('.')[1])\n",
    "    faces = face_detector.detectMultiScale(img_numpy)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        face_samples.append(img_numpy[y:y+h, x:x+w])\n",
    "        face_ids.append(face_id)\n",
    "\n",
    "face_recognizer.train(face_samples, np.array(face_ids))\n",
    "face_recognizer.write(os.path.join('trainer', 'face_trainer.yml'))\n",
    "\n",
    "print('\\n [INFO] {0} Faces Trained.'.format(len(np.unique(face_ids))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognizing Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recoginzer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.read(os.path.join('trainer', 'face_trainer.yml'))\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "text_font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "minW = int(0.1 * cap.get(3))\n",
    "minH = int(0.1 * cap.get(4))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(minW, minH))\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        \n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        face_id, confidence = face_recognizer.predict(roi_gray)\n",
    "        \n",
    "        if confidence < 100:\n",
    "            user_name = users_label_db[face_id]\n",
    "        else:\n",
    "            user_name = 'Unknown'\n",
    "        \n",
    "        confidence = \" {0}%\".format(100 - confidence)\n",
    "        \n",
    "        cv2.putText(img, user_name, (x+5, y-5), text_font, 1, (255,255,255), 2)\n",
    "        cv2.putText(img, confidence, (x+5, y+h-5), text_font, 1, (255,255,255), 2)\n",
    "        \n",
    "    cv2.imshow('Video', img)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    \n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "print('\\n [INFO] Exiting program and cleanup stuff')\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
